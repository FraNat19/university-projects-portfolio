# -*- coding: utf-8 -*-
"""Homework1_1945581.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18LjmytTmxPgVBhTRSFaQQhJZ6e0A5Bc_
"""

# Import necessary libraries for web scraping and data manipulation
import requests
import bs4
from bs4 import BeautifulSoup
import pandas as pd
import re

# Set the URL of a specific product page on the website
url = 'https://www.national-hardware.com/p/120-chair-braces?model=N234-617'
# Custom headers to mimic a browser and avoid getting blocked by the website
headers = {'User-Agent': 'frank/1.0'}
# Send a GET request to the URL
p = requests.get(url, headers=headers)
# Check the status code of the response (200 means OK)
p.status_code

# Parse the HTML content of the page using lxml parser
page = BeautifulSoup(p.content, 'lxml')

page

# Extract the name of the product
product = page.find('h1', class_='js-product-display-name').text
product

# Extract and clean up the list of the description by removing empty lines and tab characters
description = page.find('ul', class_='list-bulleted').text.strip().split('\r\n\t\t\t\t\t\t\t\t\n\r\n\t\t\t\t\t\t\t\t\t')
description = ' · '.join(description)
description = description[:100]
description

# Extract the stock number
id_stock= page.find('div', class_='kicker').text
id_stock = id_stock.replace('Stock # ', '')
id_stock

# Define a function to scrape details from a product page
def scrape_product_details(url):
  headers = {'User-Agent': 'frank/1.0'}
  p = requests.get(url, headers=headers)
  page = BeautifulSoup(p.content, 'lxml')

  output = []

  product = page.find('h1', class_='js-product-display-name').text

  description = page.find('ul', class_='list-bulleted').text.strip().split('\r\n\t\t\t\t\t\t\t\t\n\r\n\t\t\t\t\t\t\t\t\t')
  description = ' · '.join(description)
  description = description[:100]

  id_stock= page.find('div', class_='kicker').text
  id_stock = id_stock.replace('Stock # ', '')

  return id_stock, product, description

# Test if the function works
scrape_product_details(url)

# Now the URL for the search results page for "chair"
url='https://www.national-hardware.com/search?FilterCriteria.Query=chair'
p=requests.get(url)
page=bs4.BeautifulSoup(p.content,'lxml')
# Find all product cards on the page by targeting their container
ads_tot=page.find_all('div',class_=('search-results-product__content-col'))
results=[]
# Loop through each product card
for i in ads_tot:
    ad_url_fin= str(i.a["href"])
    ad_url="https://www.national-hardware.com"+ad_url_fin
    results.append(scrape_product_details(ad_url))
# Convert the results list into a pandas DataFrame
final_file=pd.DataFrame(results, columns= ['Stock number','Title','Description'])
data = final_file.set_index('Stock number')
data

final_file

# Define a function to filter the DataFrame by exact product name
def filter_by_name(keyword):
  data=final_file
  data["Title"] = data["Title"].str.strip()
  data=data[data["Title"]==keyword]
  data.to_excel(f"Filtered_dataframe_{keyword}.xlsx", index=False)
  return data

filter_by_name('Chair Braces')

data=final_file
data["Title"] = data["Title"].str.strip()
filtered = data[data["Title"] == "Chair Braces"]
filtered